# RAG Testing with Different LLMs

This repository contains experiment comparing various Language Models (LLMs) with different approaches to handling context and information retrieval.

## Objective
To evaluate and compare the performance between:
- Traditional RAG (Retrieval Augmented Generation) pipelines
- Direct context injection using larger context windows

## Models Being Tested
- Google Flash-Lite
- ChatGPT O3-mini
- Deepseek R1

## Methodology
1. Initial testing using Docugami RAG datasets with Deepseek R1
2. Comparative testing:
    - Google Flash-Lite: Direct context injection using larger context window
    - Other LLMs: Traditional RAG pipeline implementation

## Hypothesis
Testing whether larger context windows provide better results compared to traditional RAG approaches.

## Status
ðŸš§ Work in Progress